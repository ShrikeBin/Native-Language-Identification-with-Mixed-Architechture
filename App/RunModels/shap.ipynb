{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e33e62",
   "metadata": {},
   "source": [
    "# Native Language Identification - Author Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d85031",
   "metadata": {},
   "source": [
    "### Fill with models you want to test:\n",
    "\n",
    "Possible arguments for the Model:\n",
    "- trait_name\n",
    "    - 'language'\n",
    "    - 'age'\n",
    "    - 'gender'\n",
    "    - 'political'\n",
    "    - 'mbti'\n",
    "- head_type\n",
    "    - 'Classification'\n",
    "    - 'Regression'\n",
    "    - 'MixedCNN'\n",
    "    - 'CNN' (if you changed architecture make sure it matches the one in custom heads)\n",
    "- model\n",
    "    - 'DistilBERT' - default\n",
    "    - 'MpNet'\n",
    "    - 'RoBERT'\n",
    "    - 'RoBERTLarge'\n",
    "    - 'DeBerta'\n",
    "- train\n",
    "    - 'Full' - default\n",
    "    - 'LoRA'\n",
    "    - 'Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ddcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938439b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from App.ModelWrapper.model_wrapper import Model\n",
    "\n",
    "models = [\n",
    "    Model('age', 'Regression', model='DistilBERT', train='LoRA'),\n",
    "    Model('gender', 'Classification', train='Full'),\n",
    "    Model('language', 'MixedCNN', model='RoBERTa'),\n",
    "    Model('language', 'CNN'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713f8d2",
   "metadata": {},
   "source": [
    "### Function for explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767aedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(text):\n",
    "    for model in models:\n",
    "        print(model.prediction_string(text))\n",
    "        print(model.explanation_string(text))\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dac061",
   "metadata": {},
   "source": [
    "### Test your text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(\"Query routing, the task to route user queries to different large language model (LLM) endpoints, \\\n",
    "        can be considered as a text classification problem. However, out-of-distribution queries must be handled properly, \\\n",
    "        as those could be about unrelated domains, queries in other languages, or even contain unsafe text. \\\n",
    "        Here, we thus study a guarded query routing problem, for which we first introduce the Guarded Query \\\n",
    "        Routing Benchmark (GQR-Bench, released as Python package gqr), covers three exemplary target domains \\\n",
    "        (law, finance, and healthcare), and seven datasets to test robustness against out-of-distribution queries. \\\n",
    "        We then use GQR-Bench to contrast the effectiveness and efficiency of LLM-based routing mechanisms \\\n",
    "        (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B), standard LLM-based guardrail approaches \\\n",
    "        (LlamaGuard and NVIDIA NeMo Guardrails), continuous bag-of-words classifiers \\\n",
    "        (WideMLP, fastText), and traditional machine learning models (SVM, XGBoost). \\\n",
    "        Our results show that WideMLP, enhanced with out-of-domain detection capabilities, \\\n",
    "        yields the best trade-off between accuracy (88%) and speed (<4ms). The embedding-based fastText \\\n",
    "        excels at speed (<1ms) with acceptable accuracy (80%), whereas LLMs yield the highest accuracy (91%) \\\n",
    "        but are comparatively slow (62ms for local Llama-3.1:8B and 669ms for remote GPT-4o-mini calls). \\\n",
    "        Our findings challenge the automatic reliance on LLMs for (guarded) query routing and provide \\\n",
    "        concrete recommendations for practical applications. Source code is available: this https URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(\"I love pizza, even thou im not from italy, like, do italians eaven love pizza? \\\n",
    "    they are from that country that invented it arent they? how could they not love pizza, \\\n",
    "        it's as if we did not like hambugers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
